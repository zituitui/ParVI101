\section{在欧几里得空间上的梯度流}
本节首先从梯度下降视角引出欧几里得空间上的梯度流。
考察一个经典的优化问题：
$$ \underset{x \in \mathbb{R}^{n}}{min} f(x) $$
\par
在此问题上，有经典的梯度下降算法（Gradient Descent Algorithm）：
\begin{equation}
    x_{k+1} = x_{k} - \eta_{k} \nabla f(x_{k}) %\label{GD0}
\end{equation}
其中$\eta_{k}$为第$k$步迭代的步长，
$\nabla f(x_{k})$为$f(x)$在$x_{k}$这一点上的梯度（假设$f(x)$的性质足够好）。
以上的迭代运算可被重写为：
$$ \frac{x_{k+1}-x_{k}}{\eta_{k}} =  -\nabla f(x_{k})$$
上式是如下ODE方程的显式欧拉插值

\begin{equation}
    \frac{dX(t)}{dt} =  -\nabla f(x_{k}) %\label{GD0}
\end{equation}

由此，梯度下降算法可以看作是欧几里得空间上的梯度流的离散插值形式。
现在先简单证明一下此梯度流可以保证，
在$f:\mathbb{R}^{n}\rightarrow\mathbb{R}$为凸函数时，随机过程$X(t)$是趋近于最优点的。
\begin{proof}
    令 $     g(X(t)=\frac{1}{2}\Arrowvert X(t)-x^* \Arrowvert^2)$,其中$x^*=argminf(x)$,则有：
    \begin{equation}
        \begin{aligned}
            \frac{dg(X(t))}{dt}&=\frac{dg(X(t))}{dX(t)}\frac{dX(t)}{dt}\\
           &=\langle  \frac{dX(t)}{dt},X(t)-x^*  \rangle\\
           &= - \langle  \nabla_x f(X(t)),X(t)-x^*  \rangle\\
           &=  \langle  \nabla_x f(X(t)),x^*-X(t)  \rangle\\
           &\leqslant f(x^*)-f(X(t))\\
           &\leqslant 0
        \end{aligned}
    \end{equation}
    所以$g(X(t))$随着时间$t$减小，$X(t)$逐步逼近$x^*$
\end{proof}



